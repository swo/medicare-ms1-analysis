---
title: "ms2"
author: "Scott Olesen"
output: html_document
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=7, fig.height=4, fig.path='fig/', dev=c('png', 'pdf'),
                      pdf.options(useDingbats=FALSE),
                      echo=FALSE, warning=FALSE, message=FALSE, cache=TRUE, autodep=TRUE)
import::from(tools, md5sum)
library(forcats)
```

```{r load_data, cache.extra=c(md5sum('ineq.tsv'), md5sum('results.tsv'))}
ineq = read_tsv('ineq.tsv') %>%
  group_by(drug_group, unit_type, unit) %>%
  summarize_if(is.numeric, mean) %>%
  ungroup() %>%
  mutate(mup=mean/fnz)

results = read_tsv('results.tsv')

consumption_groups = read_tsv('consumption_groups.tsv')
resistance_groups = read_tsv('resistance_groups.tsv')
possible_bug_drug = read_tsv('bug_drug.tsv')

regions = read_tsv('../../db/census-regions/census-regions.tsv') %>%
  select(state, state_abbreviation, region)

zipcodes = read_tsv('../../db/zipcode/zipcode.tsv') %>%
  select(zipcode=zip, state)

# Use the zipcode-HRR mapping from 2011
hrr = read_tsv('../../db/hrr/hrr.tsv') %>%
  filter(year==2011) %>%
  select(zipcode, hrr) %>%
  left_join(zipcodes, by='zipcode') %>%
  left_join(regions, by='state')

hrr_out = hrr %>%
  count(hrr, region) %>%
  group_by(hrr) %>%
  filter(n==max(n)) %>%
  ungroup() %>%
  select(hrr, region)

state_abg = read_tsv('abg_state.tsv')
hrr_abg = read_tsv('abg_hrr.tsv')
```

# Methods

## Consumption data

I used the same inclusion criteria as in ms. #1. I grouped the beneficiaries by state or by HRR. (When zipcode-to-HRR links differed between years, I used the one from 2014.)

Then I grouped the drugs into consumption groups:

`r kable(consumption_groups)`

For each year, in each geographical unit, for each drug group, I computed the mean consumption per capita, the fraction of beneficiaries who had at least one claim ("fraction nonzero"), and the Gini coefficient among those nonzero users.

I then took the mean of these statistics across years.

## Resistance data

I join the resistance drugs into the classes shown below:

`r kable(resistance_groups)`

The *S. aureus* antibiograms are listed as MSSA, MRSA, or plain old *S. aureus*. For tetracycline, Bactrim, and clindamycin, I didn't find any big difference in resistance patterns about the three groups, so I merged them all into one group for purposes of the analysis. For the cephalosporins, I joined MSSA and plain old *S. aureus*. (MRSA, on the other hand, had clear indications that the data were artificially set to 100% resistance. Intriguingly, it seemed like this was also the case for MSSA and the beta-lactams [penicillin and ampicillin], so I did not include those.)

I included both inpatient and outpatient data, because although inpatient resistances were mostly higher than outpatient resistances, the overall trends by state appeared to be the same for both sets of data, and the difference between in- vs. outpatient were smaller than the differences between extreme ends of the states.

I summarized the resistance data for each geographical unit with a weighted mean, where the weight was the square root of the number of isolates. (In the rare cases where the number of isolates was not reported, I put in the median number of isolates for that organism.)

## Bug/drug combinations

I started by considering these `r nrow(possible_bug_drug)` bug/drug combinations on the basis of their clinical relevance and plausibility:

`r kable(possible_bug_drug)`

For each combination, I computed three models:

- a Spearman correlation of mean claims per beneficiary $\mu$ against mean percent nonsusceptible $R$
- a linear model predicting mean resistance from the fraction $f_>$ of people who are consumers
- a linear model predicting mean resistance from $f_>$ and mean consumption among consumers $\mu_> = \mu/f_>$.

When running regressions, I weight the data points by the number of antibiograms present in that unit. (The weights in a linear regression should be proportional to $1/\sigma^2$, and we generally expect that the standard error of estimators scales like $1/\sqrt{n}$.)

# Results

## Landscape of correlations

## Spearman

The plot shows the Spearman correlation coefficient $\rho$ between resistance $R$ and mean consumption $\mu$. Two stars after the bug/drug combination implies that the adjusted $p < 0.05$, and one star means the unadjusted $p < 0.05$. Intervals show 95% confidence intervals. 

```{r hrr_spearman}
interval_plot = function(df) {
  arrange(df, estimate) %>%
  mutate(p.adj=p.adjust(p.value, method='BH')) %>%
  mutate(sig=case_when(.$p.adj < 0.05 ~ '**',
                       .$p.value < 0.05 ~ '*',
                       TRUE ~ ''),
         bug_drug=fct_inorder(str_c(bug, drug_group, sig, sep=' '))) %>% 
    ggplot(aes(x=bug_drug, y=estimate, ymin=ci_low, ymax=ci_high, color=drug_group)) +
    geom_point() +
    geom_errorbar(width=0.5) +
    coord_flip()
}

results %>%
  filter(model=='spearman', unit_type=='hrr') %>%
  interval_plot() +
  ylab("Spearman's rho") +
  ggtitle("Spearman, res. vs. mean consumption, HRR")
```

```{r state_spearman}
results %>%
  filter(model=='spearman', unit_type=='state') %>%
  interval_plot() +
  ylab("Spearman's rho") +
  ggtitle("Spearman, res. vs. mean consumption, state")
```

All the demonstrably-different-from-zero relationships are positive. This jibes with our general understanding that more consumption means more resistance.

This table has the significant and marginally significant results from the previous figure.

## Linear models

We're interested in how it is that mean consumption drives resistance. Is it at the intensive or extensive margin? We separate that by writing $\mu = f_> \mu_>$.

I run models $R \sim f_>$, that is $R^{(u)} = \beta_0 + \beta_{f_>} f_>^{(u)} + \varepsilon^{(u)}$, where the superscript $u$ indicates the geographical unit (HRR or state). The plots show $\beta_{f_>}$. This model is equivalent to one in which the population resistance $R^{(u)}$ in unit $u$ is the mean of the resistance $r_i^{(u)}$ in the individual people $i$ in unit $u$, where $r_i^{(u)}$ is $\beta_0$ if person $i$ took no drug and $\beta_0 + \beta_{f_>}$ if that person took at least one dose.

The gray line shows $\beta_{f_>} = 1$. Most confidence intervals include that line, i.e., we can explain our data with a transmission-free model where individuals who take drug have 100% resistance and others have some smaller amount. In only one case do we have a place where the data are inconsistent with this simple model. (Note that the $\beta_0$ can mean the resistance among non-consumers or the fraction of non-consumers who are cryptic consumers.)

```{r hrr_linear}
results %>%
  filter(model=='univariate_fnz', unit_type=='hrr', term=='fnz') %>%
  interval_plot() +
  geom_hline(yintercept=1, col='gray') +
  ylab(expression(beta[f['>']])) +
  ggtitle("Linear univariate, HRR")
```

```{r state_linear}
results %>%
  filter(model=='univariate_fnz', unit_type=='state', term=='fnz') %>%
  interval_plot() +
  ylab(expression(beta[f['>']])) +
  ggtitle("Linear univariate, state")
```

Why should the linear models do so much better than the Spearman? I think it's because, in the linear model, I can weight the geographical units that have more antibiograms. That is, we give more weight to the greater amounts of data. The Spearman model treats them all equally.

# Unevenness of consumption and antibiotic resistance

## Unevenness is mostly related to the "extensive margin"

The line has slope 1.5.

```{r fnz_mean_drug}
cbbPalette <- c("#000000", "#D55E00", "#CC79A7", "#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2")

ineq %>%
  filter(unit_type=='state', drug_group != 'overall') %>%
  ggplot(aes(x=fnz, y=mean, color=drug_group)) +
  geom_abline(slope=1.5, color='gray') +
  geom_point() +
  xlab('Fraction nonzero') + ylab('claims per beneficiary') +
  ggtitle('Fraction consuming and mean consumption, states') +
  theme_minimal() +
  scale_color_manual(values=cbbPalette)
```

Because $f_>$ is so collinear with $\mu$, multiple regressions using both as predictors will cause problems (cf. the Supplement). Rather than mean consumption $\mu$, I'll use the mean consumption among consumers $\mu_> = \mu / f_>$ as my second predictor.

```{r fnz_mup}
ineq %>%
  filter(unit_type=='state', drug_group != 'overall') %>%
  ggplot(aes(x=fnz, y=mup, color=drug_group)) +
  geom_smooth(method='lm', se=F) +
  geom_point() +
  xlab(expression(f['>'])) +
  ylab(expression(mu['>'])) +
  ggtitle('Mean nonzero consumption vs. fraction consuming, states') +
  theme_minimal() +
  scale_color_manual(values=cbbPalette)
```

The tetracyclines and Bactrim are the interesting exceptions: in these drugs, states where consumption is more widespread are the states where consumption per consumer is lower. (The trend in clindamycin is not significant.) For tetracyclines, there appear to be downward trends within regions (except the Northeast, where the trend is up). For Bactrim, there's a Simpson's paradox: the trend is down overall, and down for the South, but it's up for all the other regions.

In both cases, it seems like the South is the mass with the most leverage, and it leverages downward.

For $\beta$-lactams, cephalosporins, clindamycin, macrolides, and quinolones, the slopes seem to mostly agree with one another. This suggests that tetracycline and Bactrim prescribing are somehow quite variable between regions.

```{r fnz_mup_by_drug}
ineq %>%
  filter(unit_type=='hrr') %>%
  filter(mup < 2.2) %>% # get rid of one outlier
  mutate(hrr=as.integer(unit)) %>% left_join(hrr_out, by='hrr') %>%
  ggplot(aes(x=fnz, y=mup, color=region)) +
  facet_wrap(~drug_group, scales='free') +
  geom_smooth(method='lm', se=F, aes(color=NULL), color='gray') +
  geom_smooth(method='lm', se=F) +
  geom_point(shape=1) +
  xlab(expression(f['>'])) +
  ylab(expression(mu['>'])) +
  ggtitle('Mean nonzero consumption vs. fraction consuming, states') +
  theme_minimal()
```

Tetracycline and Bactrim are interesting: the South has this long tail where $f_>$ is exceptionally high and $\mu_>$ is low. I imagined a model where the South was like the Midwest, but just with more people taking one does of, say, Bactrim. So it goes from $d$ doses into $c$ consumers to $d + \Delta c$ doses into $c + \Delta c$ consumers. This predicts that $\mu'_> = (\mu_> + \Delta f_>)/(1 + \Delta f_>)$. This prediction is too high: it's not *just* that more people in some parts of the South are getting these drugs; it's also that those getting the drug are getting less of it.

## The South has more consumers per capita

However, among those people who do consume, consumption is smaller per capita (i.e., the slope is similar but the intercept is smaller). In this sense, consumption in the South is less concentrated than in the Midwest.

```{r fnz_mean_region}
ineq %>%
  filter(unit_type=='state', drug_group == 'overall') %>%
  rename(state=unit) %>%
  filter(state != 'DC') %>%
  left_join(regions, by='state') %>%
  ggplot(aes(x=fnz, y=mean, color=region)) +
  geom_smooth(aes(color=NULL), method='lm', se=F, color='gray') +
  geom_point() +
  xlab('Fraction nonzero') + ylab('claims per beneficiary') +
  ggtitle('All antibiotics, f> and mean consumption, states') +
  theme_minimal()
```

## Effect of unevenness on antibiotic resistance

We ask if mean consumption $\mu$ has any information beyond fraction nonzero $f_>$ for predicting resistance $R$. We might expect that the simple two-part model represented by the regressions $R \sim f_>$ doesn't capture the fact that taking two doses should have a greater effect than taking one, etc.

These plots show the coefficient $\beta_\mu$ from the regression $R^{(u)} = \beta_0 + \beta_{f_>} f_>^{(u)} + \beta_\mu \mu^{(u)} + \varepsilon^{(u)}$.

```{r hrr_multi}
results %>%
  filter(model=='multivariate_fnz_mup', unit_type=='hrr', term=='mup') %>%
  interval_plot() +
  ylab(expression(beta[mu['>']])) +
  ggtitle("Linear multivariate (f> and mu>), HRR")
```

At the state level, none of the $\beta_\mu$ coefficients are significantly different from zero (after multiple-hypothesis correction).

```{r state_multi}
results %>%
  filter(model=='multivariate_fnz_mean', unit_type=='state', term=='mean') %>%
  interval_plot() +
  ylab(expression(beta[mu])) +
  ggtitle("Linear multivariate (f> and mean), state")
```

There are a few significant results:

- *E. coli* and Bactrim have a *negative* relationship (higher consumption goes with *less* resistance)
- *S. pneumoniae* and tetracyclines have a negative relationship
- *E. faecium* and $\beta$-lactams have a positive relationship (implying higher mean consumption, given the same fraction of people consuming, goes with more resistance)

Interestingly, these are the same three values that are significant when performing the (ill-advised) regression using $f_>$ and $\mu$. The table shows that bug/drug combinations in which the multiple regressions have significantly non-zero $\beta_{\mu_>}$. The values in the columns show the estimates of $\beta$ in each model. Note the big differences in $\beta_{f_>}$ between the two models. Note that although the regression $R \sim f_> + \mu$ distorts $\beta_{f_>}$ more than the regression $R \sim f_> + \mu_>$, the coefficient still gets changed quite a bit nonetheless. We were hoping for $\mu_>$ to give information in addition to $f_>$, not to just change it completely.

```{r fnz_mu_results}
results %>%
  filter(unit_type=='hrr', model %in% c('univariate_fnz', 'multivariate_fnz_mean', 'multivariate_fnz_mup'), term != '(Intercept)') %>%
  (function(df) {
    filter(df, term != 'fnz', p.adjust(p.value, method='BH') < 0.05) %>%
      select(bug, drug_group) %>%
      distinct() %>%
      inner_join(df, by=c('bug', 'drug_group')) }) %>%
  mutate(model=str_replace(model, '^multivariate_', '')) %>%
  select(bug, drug_group, model, term, estimate) %>%
  spread(term, estimate) %>%
  kable
```

For *E. faecium* with $\beta$-lactams, the univariate regression with $f_>$ gives a slightly negative slope but is not significant. The univariate regression with $\mu$ gives a slightly positive slope and is not significant. In the multiple regression, the signs stay the same but the coefficients are very different. Thus, we can't trust that $\mu$ provides data in addition to $f_>$ when it's not clear that either provides the information on its own.

For *S. pneumoniae* and tetracyclines, the regression with $f_>$ and the regression with $\mu$ give negative slopes, but neither are significant. In the multiple regression, the $f_>$ coefficient becomes positive. Again, I'm not sure I can trust this.

For *E. coli* and Bactrim, the univariate regression with $f_>$ is positive and signficant. The regression with $\mu$ is positive and not significant. Then, in the multiple regression, $\mu$ flips signs and becomes highly significant (different from zero), and it's significant in an ANOVA where $f_>$ comes first, but it's not significant in an ANOVA where it ($\mu$) comes first.

### E. coli and Bactrim

This negative relationship is the most tricky.

From the Spearman and univariate models, Bactrim resistance in *E. coli* is correlated with increased resistance (black line). When breaking that apart by region, however, there are different relationship (colored lines). This makes it seem like there is something strange going on.

It's the L-shape!

```{r ecoli_bactrim_fnz_hrr}
ineq %>%
  filter(unit_type=='hrr') %>%
  mutate(hrr=as.integer(unit)) %>% left_join(hrr_out, by='hrr') %>%
  right_join(hrr_abg, by=c('hrr', 'drug_group')) %>%
  filter(bug=='E. coli', drug_group=='tmp_smx') %>%
  filter(mean_percent_nonsusceptible < 50) %>% # filter one crazy Nevada point
  ggplot(aes(x=fnz, y=mean_percent_nonsusceptible, color=region)) +
  geom_abline(intercept=16.86, slope=114.8, color='pink') +
  geom_smooth(method='lm', se=F, aes(color=NULL), color='black') +
  geom_smooth(method='lm', se=F) +
  geom_point() +
  xlab('fraction who consumed Bactrim') +
  ylab('Bactrim-resistance E. coli') +
  ggtitle('E. coli & Bactrim across HRRs')
```

These internal trends are a lot weaker when looking at the state level:

```{r ecoli_bactrim_fnz_state}
ineq %>%
  filter(unit_type=='state') %>%
  rename(state=unit) %>%
  left_join(regions, by='state') %>%
  right_join(state_abg, by=c('state', 'drug_group')) %>%
  filter(bug=='E. coli', drug_group=='tmp_smx') %>%
  ggplot(aes(x=fnz, y=mean_percent_nonsusceptible, color=region)) +
  geom_smooth(method='lm', se=F, aes(color=NULL), color='black') +
  geom_smooth(method='lm', se=F) +
  geom_point() +
  xlab('fraction who consumed Bactrim') +
  ylab('Bactrim resistance E. coli') +
  ggtitle('E. coli & Bactrim across states')
```

But the same patterns are visible when looking at $\mu_>$ across HRRs:

```{r ecoli_bactrim_mup}
ineq %>%
  filter(unit_type=='hrr') %>%
  mutate(hrr=as.integer(unit)) %>% left_join(hrr_out, by='hrr') %>%
  right_join(hrr_abg, by=c('hrr', 'drug_group')) %>%
  filter(bug=='E. coli', drug_group=='tmp_smx') %>%
  filter(mean_percent_nonsusceptible < 50) %>% # filter one crazy Nevada point
  ggplot(aes(x=mean, y=mean_percent_nonsusceptible, color=region)) +
  geom_smooth(method='lm', se=F, aes(color=NULL), color='black') +
  geom_smooth(method='lm', se=F) +
  geom_point() +
  xlab('mean Bactrim cons. among Bactrim-eaters') +
  ylab('Bactrim-resistance E. coli') +
  ggtitle('E. coli & Bactrim, mu>, HRRs')
```

### E. faecium and beta-lactams

```{r efaecium_betalactam}
ineq %>%
  filter(unit_type=='hrr') %>%
  mutate(hrr=as.integer(unit)) %>% left_join(hrr_out, by='hrr') %>%
  right_join(hrr_abg, by=c('hrr', 'drug_group')) %>%
  filter(bug=='Ec. faecium', drug_group=='beta_lactam') %>%
  ggplot(aes(x=fnz, y=mean_percent_nonsusceptible, color=region)) +
  geom_smooth(method='lm', se=F, aes(color=NULL), color='black') +
  geom_smooth(method='lm', se=F) +
  geom_point() +
  xlab('fraction who consumed beta-lactams') +
  ylab('Beta-lactam resistance in E. faecium') +
  ggtitle('E. faecium & beta-lactams across HRRs')

ineq %>%
  filter(unit_type=='state') %>%
  rename(state=unit) %>%
  left_join(regions, by='state') %>%
  right_join(state_abg, by=c('state', 'drug_group')) %>%
  filter(bug=='Ec. faecium', drug_group=='beta_lactam') %>%
  ggplot(aes(x=mean, y=mean_percent_nonsusceptible, color=region)) +
  geom_smooth(method='lm', se=F, aes(color=NULL), color='black') +
  geom_smooth(method='lm', se=F) +
  geom_point() +
  xlab('fraction who consumed beta-lactams') +
  ylab('Beta-lactam resistance E. coli') +
  ggtitle('E. faecium & beta-lactams across states')
```

### S. pneumonia and tetracyclines

```{r pneumo_tetra}
ineq %>%
  filter(unit_type=='hrr') %>%
  mutate(hrr=as.integer(unit)) %>% left_join(hrr_out, by='hrr') %>%
  right_join(hrr_abg, by=c('hrr', 'drug_group')) %>%
  filter(bug=='S. pneumoniae', drug_group=='tetracycline') %>%
  ggplot(aes(x=fnz, y=mean_percent_nonsusceptible, color=region)) +
  geom_smooth(method='lm', se=F, aes(color=NULL), color='black') +
  geom_smooth(method='lm', se=F) +
  geom_point() +
  xlab('fraction who consumed tetra') +
  ylab('tetra resistance pneumo') +
  ggtitle('pneumo & tetra across HRRs')

ineq %>%
  filter(unit_type=='state') %>%
  rename(state=unit) %>%
  left_join(regions, by='state') %>%
  right_join(state_abg, by=c('state', 'drug_group')) %>%
  filter(bug=='S. pneumoniae', drug_group=='tetracycline') %>%
  ggplot(aes(x=fnz, y=mean_percent_nonsusceptible, color=region)) +
  geom_smooth(method='lm', se=F, aes(color=NULL), color='black') +
  geom_smooth(method='lm', se=F) +
  geom_point() +
  xlab('fraction who consumed tetra') +
  ylab('tetra resistance pneumo') +
  ggtitle('pneumo & tetra across states')
```

### E. coli and beta-lactams

This negative relationship was significant only for HRRs, not states. Not surprisingly, there is something weird going on with the HRRs: the Southern HRRs are all above the $R \sim f_>$ line, suggesting that the relationship with the mean is just a predictor about region.

```{r ecoli_betalactam}
ineq %>%
  filter(unit_type=='hrr') %>%
  mutate(hrr=as.integer(unit)) %>% left_join(hrr_out, by='hrr') %>%
  right_join(hrr_abg, by=c('hrr', 'drug_group')) %>%
  filter(bug=='E. coli', drug_group=='beta_lactam') %>%
  filter(mean_percent_nonsusceptible < 50) %>% # filter one crazy Nevada point
  ggplot(aes(x=fnz, y=mean_percent_nonsusceptible, color=region)) +
  geom_smooth(method='lm', se=F, aes(color=NULL), color='black') +
  geom_smooth(method='lm', se=F) +
  geom_point() +
  xlab('fraction who consumed beta-lactams') +
  ylab('Beta-lactam resistance in E. coli') +
  ggtitle('E. coli & beta-lactams across HRRs')

ineq %>%
  filter(unit_type=='state') %>%
  rename(state=unit) %>%
  left_join(regions, by='state') %>%
  right_join(state_abg, by=c('state', 'drug_group')) %>%
  filter(bug=='E. coli', drug_group=='beta_lactam') %>%
  filter(mean_percent_nonsusceptible < 50) %>% # filter one crazy point
  ggplot(aes(x=mean, y=mean_percent_nonsusceptible, color=region)) +
  geom_smooth(method='lm', se=F, aes(color=NULL), color='black') +
  geom_smooth(method='lm', se=F) +
  geom_point() +
  xlab('fraction who consumed beta-lactams') +
  ylab('Beta-lactam resistance E. coli') +
  ggtitle('E. coli & beta-lactams across states')
```

## Comparing the predictive power of mean consumption and fraction nonzero

How do the regressions $R \sim f_>$ compare to $R \sim \mu$? Here I look at the correlation between the coefficients $\beta_\mu$ and $\beta_{f_>}$ across bug/drug combinations. Not surprisingly, $\beta_\mu$ and $\beta_{f_>}$ are highly correlated: because $\mu$ and $f_>$ are correlated, you can guess the result of the one regression from the other. However, $\beta_{\mu_>}$ is not as well correlated with $\beta_{f_>}$, indicating that there might be some extra information there.

The column titles are `metric1_metric2`, and the value shows the correlation between the univariate models' coefficients for predicting resistance to that drug across bugs.

```{r univariate_result_correlation}
results %>%
  filter(str_detect(model, '^uni'), term != '(Intercept)') %>%
  select(unit_type, bug, drug_group, term, estimate) %>%
  spread(term, estimate) %>%
  group_by(unit_type, drug_group) %>%
  filter(n() > 2) %>%
  do(tidy(cor(select(., -unit_type, -bug, -drug_group)))) %>%
  ungroup() %>%
  rename(x=.rownames) %>%
  gather('y', 'value', fnz:nb_mu) %>%
  filter(x > y) %>%
  mutate(key=str_c(x, '_', y)) %>%
  select(-x, -y) %>%
  spread(key, value) %>%
  kable
```

In other words, if you do the regression with $f_>$, you can predict with very high accuracy the coefficient from the univariate regression on $\mu$.

## Specific plots

### E. coli & quinolones

```{r ecoli_quin_state}
state_cons_res_plot = function(b, d) {
  p = inner_join(
    ineq %>%
      filter(unit_type=='state', drug_group==d) %>%
      select(state=unit, mean),
    state_abg %>%
      filter(bug==b, drug_group==d) %>%
      select(state, mean_percent_nonsusceptible),
    by='state') %>%
    left_join(regions, by='state') %>%
    ggplot(aes(x=mean, y=mean_percent_nonsusceptible, label=state, color=region)) +
    geom_smooth(method='lm', se=F) +
    geom_smooth(method='lm', se=F, col='gray') +
    geom_point() +
    geom_text() +
    xlab(str_interp('mean ${d} claims per beneficiary')) +
    ylab(str_interp('mean percent nonsusceptible ${b} isolates')) +
    ggtitle(str_interp('${b} & ${d}, state'))
  
  p
}

show(state_cons_res_plot('E. coli', 'quinolone'))
```

### Pneumococcus and macrolides

```{r pneumo_macro_state}
show(state_cons_res_plot('S. pneumoniae', 'macrolide'))
```

- *E. cloacae* and quinolone
- *S. aureus* and clindamycin

# Supplementary results

## Collinearity

This shows why it's a bad idea to do a multiple regression with $f_>$ and $\mu$. It confirms that we're mostly getting bad results due to multicollinearity.

The gray lines link the coefficients from a univariate model and a multivariate model (i.e., with $f_>$ and $\mu$) for a certain bug/drug combination.

From a previous plot, we know that $\mu \approx \alpha f_>$, where $\alpha \approx 3/2$. Then if $R \approx \beta_0 + \beta_{f_>}$, then we should guess that $\beta_\mu = \beta_{f_>} / \alpha$.

Furthermore, in doing a multivariate regression, using the same math, we find that we expect
$$
\beta_\mu^{(2)} = \frac{1}{\alpha} \left( \beta_{f_>}^{(1)} - \beta_{f_>}^{(2)} \right),
$$
where the superscripts indicate that the coefficients are from the univariate ("1") and multivariate ("2") regressions. Thus, for $\beta_{f_>}^{(1)} \approx 0$, we expect the multivariate regression coefficients be related by a slope of $-1/\alpha$.

On this plot, the pink lines show $\pm 1/\alpha$, which lines up very nicely with the data (especially considering that I picked $\alpha=3/2$ just by eyeballing that other plot).

```{r uni_multi}
results %>%
  filter(unit_type=='hrr', term != '(Intercept)',
         model %in% c('univariate_fnz', 'univariate_mean', 'multivariate_fnz_mean')) %>%
  mutate(model=str_extract(model, '(uni|multi)'),
         bug_drug=interaction(bug, drug_group)) %>%
  select(bug_drug, model, term, estimate) %>%
  spread(term, estimate) %>%
  ggplot(aes(x=fnz, y=mean, color=model, group=bug_drug)) +
  geom_abline(slope=2/3, color='pink') +
  geom_abline(slope=-2/3, intercept=0, color='pink') +
  geom_line(color='gray') +
  geom_point() +
  xlab(expression(beta[f['>']])) +
  ylab(expression(beta[mu])) +
  ggtitle('Relationship between model coefficients (f>, mean), HRR')
```

But the result is not so pronounced for $f_>$ and $\mu_>$:

```{r uni_multi_mup}
results %>%
  filter(unit_type=='hrr', term != '(Intercept)',
         model %in% c('univariate_fnz', 'univariate_mup', 'multivariate_fnz_mup')) %>%
  mutate(model=str_extract(model, '(uni|multi)'),
        bug_drug=str_c(bug, drug_group)) %>%
  select(bug_drug, model, term, estimate) %>%
  spread(term, estimate) %>%
  ggplot(aes(x=fnz, y=mup, color=model, group=bug_drug, label=bug_drug)) +
  #geom_text(size=2) +
  geom_line(color='gray') +
  geom_point() +
  xlab(expression(beta[f['>']])) +
  ylab(expression(beta[mu['>']])) +
  ggtitle('Relationship between model coefficients (f>, mu>) , HRR')
```

## Correlations between the metrics

The mean and the fraction nonzero are highly correlated ($\rho \sim 1$) for all drug groups. (Note the range on the $x$-axis!)

```{r metrics}
f = function(df, x, y) {
  cor.test(df[[x]], df[[y]], method='spearman') %>% tidy
}

ineq %>%
  group_by(unit_type, drug_group) %>%
  do(f(., 'fnz', 'mean')) %>%
  ungroup() %>%
  select(unit_type, drug_group, estimate, p.value) %>%
  ggplot(aes(x=drug_group, y=estimate, color=unit_type)) +
  geom_point() +
  ylab('Spearman correlation between metrics') +
  coord_flip()
```

## Comparing state and HRR Spearman models

Each point shows the $\rho$ and $p$-value from a Spearman correlation test for a bug/drug combination in a geographic unit (state or HRR). Gray lines connect the two points representing the test for the same bug/drug combination; one point is for states, the other for HRRs.

It seems like the states generally have more positive estimates. I wonder if that means that states are the "correct" geographical level at which to look at these effects, but there just aren't enough of them to be able to make a sufficiently small $p$-value.

The dumbbells that cross the black, $p = 0.05$ line are the ones that are significant for one geographical unit but not the other.

```{r spearman_state_hrr_compare}
results %>%
  filter(model=='spearman') %>%
  mutate(group=interaction(bug, drug_group),
         adj.p.value=p.adjust(p.value, method='BH')) %>%
  ggplot(aes(x=estimate, y=-log10(adj.p.value), color=unit_type, group=group)) +
  geom_line(color='gray') +
  geom_hline(yintercept=-log10(0.05)) +
  geom_point() +
  xlab("Spearman's rho")
```
